{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0640b323-eab9-4ebc-9254-b1e2c08d5dc3",
   "metadata": {},
   "source": [
    "# All the data stuffs\n",
    "### this is the file for basic preprocessing and data manipulation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17ef7a9291641381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import expit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ff71912-164a-4be2-ab98-e94890cf7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting a random seed for reproducibility\n",
    "random.seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc1b61be-7db6-4e49-91d9-3a06fc824ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the data\n",
    "with open('realAccountData.json', 'r') as f:\n",
    "            realData = json.load(f)\n",
    "with open('fakeAccountData.json', 'r') as f:\n",
    "            fakeData = json.load(f)\n",
    "allData = realData + fakeData #note that the data is ordered right now\n",
    "random.shuffle(allData) #so this shuffles the list just in case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331f931-bd2f-4596-848e-a75deb4f4026",
   "metadata": {},
   "source": [
    "### making numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f284e590-d29b-41d1-975d-5b017e96df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning into numpy arrays if thats needed\n",
    "numpy_real = np.array(realData)\n",
    "# print(numpy_real[1]) #making sure things work\n",
    "numpy_fake = np.array(fakeData)\n",
    "# print(numpy_fake[1]) #making sure things work\n",
    "numpy_all = np.array(allData)\n",
    "# print(numpy_all[1]) #making sure things work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9827eed0-f563-48d0-b3e8-e06c749fc2c1",
   "metadata": {},
   "source": [
    "### making pandas databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6de4dc07-7afe-4a63-ac86-0fe3944694d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData_df = pd.DataFrame(allData)\n",
    "\n",
    "#adding the ones and seperating the data\n",
    "allData_df.insert(0, 'Ones', 1)\n",
    "cols = allData_df.shape[1]\n",
    "X = allData_df.iloc[:,0:cols-1] # iloc slicing function\n",
    "Y = allData_df.iloc[:,cols-1:cols]\n",
    "\n",
    "# display(allData_df) #making sure this works\n",
    "# display(X) #making sure this works\n",
    "# display(Y) #making sure this works\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde467b-23ef-4a41-86d0-4f9586af6063",
   "metadata": {},
   "source": [
    "### making a train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c312d7-7ffb-4dec-87ff-537f4216dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split being made\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "# and normalizing the X data\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "#if y needs to be an array\n",
    "y_array = np.ravel(Y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.25, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9848069a-dca6-4530-91bc-16f3eb32da5a",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bae17332-7d4f-460e-b7bd-d5ec091f710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataViz(model, x_test, y_test):\n",
    "\n",
    "    \n",
    "    y_pred = model.predict(X = x_test)\n",
    "    conf_matrix = confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "    conf_matrix_scaler = preprocessing.StandardScaler().fit(conf_matrix) #scaling to avoid difference in scales\n",
    "    conf_matrix_scaled = conf_matrix_scaler.transform(conf_matrix)\n",
    "    \n",
    "    plt.title('Confusion Matrix Heat Map')\n",
    "    plt.imshow(conf_matrix_scaled)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"True Class\")\n",
    "    plt.ylabel(\"Predicted Class\")\n",
    "    plt.show()\n",
    "\n",
    "    class_report = classification_report(y_true = y_test, y_pred = y_pred)\n",
    "    print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7509e4-38f4-4dac-a36b-a6cf40ea490a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
